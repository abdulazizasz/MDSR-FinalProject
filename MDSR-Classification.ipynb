{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report - Preprocessing & Language Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is heavily adapted from the following resources  \n",
    "\n",
    "# https://towardsdatascience.com/solving-a-simple-classification-problem-with-python-fruits-lovers-edition-d20ab6b071d2\n",
    "# https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "# https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python\n",
    "# https://www.kaggle.com/rcushen/topic-modelling-with-lsa-and-lda\n",
    "# https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abdulaziz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "import nltk\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "import urllib.request, urllib.error\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers, models, optimizers\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "nltk.download('stopwords')  \n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the repository list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': '1', 'reponame': 'twbs', 'description': 'bootstrap', 'updateDate': \"['the', 'most', 'popular', 'html', ',', 'css', ',', 'and', 'javascript', 'framework', 'for', 'developing', 'responsive', ',', 'mobile', 'first', 'projects', 'on', 'the', 'web', '.']\", 'language': '2017-06-24T15:40:21Z', 'stars': 'JavaScript', 'tags': '112k', 'url': \"['javascript', 'css', 'html', 'bootstrap', 'jekyll', 'site', 'scss']\"}\n"
     ]
    }
   ],
   "source": [
    "with open('./data/TopStaredRepositories.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    templist = list(reader)\n",
    "repoheader=templist[0]\n",
    "repolist=templist[1:]\n",
    "# print(repoheader)\n",
    "\n",
    "repos=[]\n",
    "for line in repolist:\n",
    "    repos.append({'username':line[0],'reponame':line[1],'description':line[2],\n",
    "                  'updateDate':line[3],'language':line[4],'stars':line[5],'tags':line[6],'url':line[7]})\n",
    "print(repos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/0/freeCodeCamp/master/README.md\n",
      "Error in freeCodeCamp\n",
      "https://raw.githubusercontent.com/1/twbs/master/README.md\n",
      "Error in twbs\n",
      "https://raw.githubusercontent.com/2/EbookFoundation/master/README.md\n",
      "Error in EbookFoundation\n",
      "https://raw.githubusercontent.com/3/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/4/d3/master/README.md\n",
      "Error in d3\n",
      "https://raw.githubusercontent.com/5/getify/master/README.md\n",
      "Error in getify\n",
      "https://raw.githubusercontent.com/6/tensorflow/master/README.md\n",
      "Error in tensorflow\n",
      "https://raw.githubusercontent.com/7/sindresorhus/master/README.md\n",
      "Error in sindresorhus\n",
      "https://raw.githubusercontent.com/8/vuejs/master/README.md\n",
      "Error in vuejs\n",
      "https://raw.githubusercontent.com/9/angular/master/README.md\n",
      "Error in angular\n",
      "https://raw.githubusercontent.com/10/robbyrussell/master/README.md\n",
      "Error in robbyrussell\n",
      "https://raw.githubusercontent.com/11/airbnb/master/README.md\n",
      "Error in airbnb\n",
      "https://raw.githubusercontent.com/12/github/master/README.md\n",
      "Error in github\n",
      "https://raw.githubusercontent.com/13/FortAwesome/master/README.md\n",
      "Error in FortAwesome\n",
      "https://raw.githubusercontent.com/14/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/15/electron/master/README.md\n",
      "Error in electron\n",
      "https://raw.githubusercontent.com/16/torvalds/master/README.md\n",
      "Error in torvalds\n",
      "https://raw.githubusercontent.com/17/jquery/master/README.md\n",
      "Error in jquery\n",
      "https://raw.githubusercontent.com/18/jwasham/master/README.md\n",
      "Error in jwasham\n",
      "https://raw.githubusercontent.com/19/moby/master/README.md\n",
      "Error in moby\n",
      "https://raw.githubusercontent.com/20/daneden/master/README.md\n",
      "Error in daneden\n",
      "https://raw.githubusercontent.com/21/apple/master/README.md\n",
      "Error in apple\n",
      "https://raw.githubusercontent.com/22/atom/master/README.md\n",
      "Error in atom\n",
      "https://raw.githubusercontent.com/23/meteor/master/README.md\n",
      "Error in meteor\n",
      "https://raw.githubusercontent.com/24/h5bp/master/README.md\n",
      "Error in h5bp\n",
      "https://raw.githubusercontent.com/25/nodejs/master/README.md\n",
      "Error in nodejs\n",
      "https://raw.githubusercontent.com/26/nodejs/master/README.md\n",
      "Error in nodejs\n",
      "https://raw.githubusercontent.com/27/rails/master/README.md\n",
      "Error in rails\n",
      "https://raw.githubusercontent.com/28/Semantic-Org/master/README.md\n",
      "Error in Semantic-Org\n",
      "https://raw.githubusercontent.com/29/vinta/master/README.md\n",
      "Error in vinta\n",
      "https://raw.githubusercontent.com/30/hakimel/master/README.md\n",
      "Error in hakimel\n",
      "https://raw.githubusercontent.com/31/socketio/master/README.md\n",
      "Error in socketio\n",
      "https://raw.githubusercontent.com/32/mrdoob/master/README.md\n",
      "Error in mrdoob\n",
      "https://raw.githubusercontent.com/33/laravel/master/README.md\n",
      "Error in laravel\n",
      "https://raw.githubusercontent.com/34/expressjs/master/README.md\n",
      "Error in expressjs\n",
      "https://raw.githubusercontent.com/35/reactjs/master/README.md\n",
      "Error in reactjs\n",
      "https://raw.githubusercontent.com/36/moment/master/README.md\n",
      "Error in moment\n",
      "https://raw.githubusercontent.com/37/impress/master/README.md\n",
      "Error in impress\n",
      "https://raw.githubusercontent.com/38/nwjs/master/README.md\n",
      "Error in nwjs\n",
      "https://raw.githubusercontent.com/39/jlevy/master/README.md\n",
      "Error in jlevy\n",
      "https://raw.githubusercontent.com/40/chartjs/master/README.md\n",
      "Error in chartjs\n",
      "https://raw.githubusercontent.com/41/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/42/jakubroztocil/master/README.md\n",
      "Error in jakubroztocil\n",
      "https://raw.githubusercontent.com/43/ionic-team/master/README.md\n",
      "Error in ionic-team\n",
      "https://raw.githubusercontent.com/44/jekyll/master/README.md\n",
      "Error in jekyll\n",
      "https://raw.githubusercontent.com/45/Microsoft/master/README.md\n",
      "Error in Microsoft\n",
      "https://raw.githubusercontent.com/46/webpack/master/README.md\n",
      "Error in webpack\n",
      "https://raw.githubusercontent.com/47/resume/master/README.md\n",
      "Error in resume\n",
      "https://raw.githubusercontent.com/48/AFNetworking/master/README.md\n",
      "Error in AFNetworking\n",
      "https://raw.githubusercontent.com/49/golang/master/README.md\n",
      "Error in golang\n",
      "https://raw.githubusercontent.com/50/facebookincubator/master/README.md\n",
      "Error in facebookincubator\n",
      "https://raw.githubusercontent.com/51/Homebrew/master/README.md\n",
      "Error in Homebrew\n",
      "https://raw.githubusercontent.com/52/nvbn/master/README.md\n",
      "Error in nvbn\n",
      "https://raw.githubusercontent.com/53/h5bp/master/README.md\n",
      "Error in h5bp\n",
      "https://raw.githubusercontent.com/54/pallets/master/README.md\n",
      "Error in pallets\n",
      "https://raw.githubusercontent.com/55/NARKOZ/master/README.md\n",
      "Error in NARKOZ\n",
      "https://raw.githubusercontent.com/56/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/57/adobe/master/README.md\n",
      "Error in adobe\n",
      "https://raw.githubusercontent.com/58/Dogfalo/master/README.md\n",
      "Error in Dogfalo\n",
      "https://raw.githubusercontent.com/59/blueimp/master/README.md\n",
      "Error in blueimp\n",
      "https://raw.githubusercontent.com/60/rg3/master/README.md\n",
      "Error in rg3\n",
      "https://raw.githubusercontent.com/61/necolas/master/README.md\n",
      "Error in necolas\n",
      "https://raw.githubusercontent.com/62/gulpjs/master/README.md\n",
      "Error in gulpjs\n",
      "https://raw.githubusercontent.com/63/callemall/master/README.md\n",
      "Error in callemall\n",
      "https://raw.githubusercontent.com/64/jashkenas/master/README.md\n",
      "Error in jashkenas\n",
      "https://raw.githubusercontent.com/65/django/master/README.md\n",
      "Error in django\n",
      "https://raw.githubusercontent.com/66/yarnpkg/master/README.md\n",
      "Error in yarnpkg\n",
      "https://raw.githubusercontent.com/67/requests/master/README.md\n",
      "Error in requests\n",
      "https://raw.githubusercontent.com/68/zurb/master/README.md\n",
      "Error in zurb\n",
      "https://raw.githubusercontent.com/69/angular/master/README.md\n",
      "Error in angular\n",
      "https://raw.githubusercontent.com/70/ReactiveX/master/README.md\n",
      "Error in ReactiveX\n",
      "https://raw.githubusercontent.com/71/chrislgarry/master/README.md\n",
      "Error in chrislgarry\n",
      "https://raw.githubusercontent.com/72/kubernetes/master/README.md\n",
      "Error in kubernetes\n",
      "https://raw.githubusercontent.com/73/lodash/master/README.md\n",
      "Error in lodash\n",
      "https://raw.githubusercontent.com/74/Alamofire/master/README.md\n",
      "Error in Alamofire\n",
      "https://raw.githubusercontent.com/75/antirez/master/README.md\n",
      "Error in antirez\n",
      "https://raw.githubusercontent.com/76/wasabeef/master/README.md\n",
      "Error in wasabeef\n",
      "https://raw.githubusercontent.com/77/ansible/master/README.md\n",
      "Error in ansible\n",
      "https://raw.githubusercontent.com/78/getlantern/master/README.md\n",
      "Error in getlantern\n",
      "https://raw.githubusercontent.com/79/josephmisiti/master/README.md\n",
      "Error in josephmisiti\n",
      "https://raw.githubusercontent.com/80/kamranahmedse/master/README.md\n",
      "Error in kamranahmedse\n",
      "https://raw.githubusercontent.com/81/papers-we-love/master/README.md\n",
      "Error in papers-we-love\n",
      "https://raw.githubusercontent.com/82/elastic/master/README.md\n",
      "Error in elastic\n",
      "https://raw.githubusercontent.com/83/Trinea/master/README.md\n",
      "Error in Trinea\n",
      "https://raw.githubusercontent.com/84/neovim/master/README.md\n",
      "Error in neovim\n",
      "https://raw.githubusercontent.com/85/Microsoft/master/README.md\n",
      "Error in Microsoft\n",
      "https://raw.githubusercontent.com/86/nylas/master/README.md\n",
      "Error in nylas\n",
      "https://raw.githubusercontent.com/87/ReactTraining/master/README.md\n",
      "Error in ReactTraining\n",
      "https://raw.githubusercontent.com/88/TryGhost/master/README.md\n",
      "Error in TryGhost\n",
      "https://raw.githubusercontent.com/89/johnpapa/master/README.md\n",
      "Error in johnpapa\n",
      "https://raw.githubusercontent.com/90/typicode/master/README.md\n",
      "Error in typicode\n",
      "https://raw.githubusercontent.com/91/ariya/master/README.md\n",
      "Error in ariya\n",
      "https://raw.githubusercontent.com/92/open-source-society/master/README.md\n",
      "Error in open-source-society\n",
      "https://raw.githubusercontent.com/93/tiimgreen/master/README.md\n",
      "Error in tiimgreen\n",
      "https://raw.githubusercontent.com/94/rust-lang/master/README.md\n",
      "Error in rust-lang\n",
      "https://raw.githubusercontent.com/95/square/master/README.md\n",
      "Error in square\n",
      "https://raw.githubusercontent.com/96/discourse/master/README.md\n",
      "Error in discourse\n",
      "https://raw.githubusercontent.com/97/firehol/master/README.md\n",
      "Error in firehol\n",
      "https://raw.githubusercontent.com/98/dypsilon/master/README.md\n",
      "Error in dypsilon\n",
      "https://raw.githubusercontent.com/99/mzabriskie/master/README.md\n",
      "Error in mzabriskie\n",
      "https://raw.githubusercontent.com/100/avelino/master/README.md\n",
      "Error in avelino\n",
      "https://raw.githubusercontent.com/101/caolan/master/README.md\n",
      "Error in caolan\n",
      "https://raw.githubusercontent.com/102/babel/master/README.md\n",
      "Error in babel\n",
      "https://raw.githubusercontent.com/103/tastejs/master/README.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in tastejs\n",
      "https://raw.githubusercontent.com/104/minimaxir/master/README.md\n",
      "Error in minimaxir\n",
      "https://raw.githubusercontent.com/105/scrapy/master/README.md\n",
      "Error in scrapy\n",
      "https://raw.githubusercontent.com/106/jashkenas/master/README.md\n",
      "Error in jashkenas\n",
      "https://raw.githubusercontent.com/107/harvesthq/master/README.md\n",
      "Error in harvesthq\n",
      "https://raw.githubusercontent.com/108/lukehoban/master/README.md\n",
      "Error in lukehoban\n",
      "https://raw.githubusercontent.com/109/Modernizr/master/README.md\n",
      "Error in Modernizr\n",
      "https://raw.githubusercontent.com/110/square/master/README.md\n",
      "Error in square\n",
      "https://raw.githubusercontent.com/111/select2/master/README.md\n",
      "Error in select2\n",
      "https://raw.githubusercontent.com/112/vsouza/master/README.md\n",
      "Error in vsouza\n",
      "https://raw.githubusercontent.com/113/adam-p/master/README.md\n",
      "Error in adam-p\n",
      "https://raw.githubusercontent.com/114/sahat/master/README.md\n",
      "Error in sahat\n",
      "https://raw.githubusercontent.com/115/enaqx/master/README.md\n",
      "Error in enaqx\n",
      "https://raw.githubusercontent.com/116/creationix/master/README.md\n",
      "Error in creationix\n",
      "https://raw.githubusercontent.com/117/iluwatar/master/README.md\n",
      "Error in iluwatar\n",
      "https://raw.githubusercontent.com/118/prakhar1989/master/README.md\n",
      "Error in prakhar1989\n",
      "https://raw.githubusercontent.com/119/gogits/master/README.md\n",
      "Error in gogits\n",
      "https://raw.githubusercontent.com/120/Unitech/master/README.md\n",
      "Error in Unitech\n",
      "https://raw.githubusercontent.com/121/alvarotrigo/master/README.md\n",
      "Error in alvarotrigo\n",
      "https://raw.githubusercontent.com/122/gitlabhq/master/README.md\n",
      "Error in gitlabhq\n",
      "https://raw.githubusercontent.com/123/karan/master/README.md\n",
      "Error in karan\n",
      "https://raw.githubusercontent.com/124/scikit-learn/master/README.md\n",
      "Error in scikit-learn\n",
      "https://raw.githubusercontent.com/125/googlesamples/master/README.md\n",
      "Error in googlesamples\n",
      "https://raw.githubusercontent.com/126/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/127/rethinkdb/master/README.md\n",
      "Error in rethinkdb\n",
      "https://raw.githubusercontent.com/128/caesar0301/master/README.md\n",
      "Error in caesar0301\n",
      "https://raw.githubusercontent.com/129/joshbuchea/master/README.md\n",
      "Error in joshbuchea\n",
      "https://raw.githubusercontent.com/130/bayandin/master/README.md\n",
      "Error in bayandin\n",
      "https://raw.githubusercontent.com/131/certbot/master/README.md\n",
      "Error in certbot\n",
      "https://raw.githubusercontent.com/132/toddmotto/master/README.md\n",
      "Error in toddmotto\n",
      "https://raw.githubusercontent.com/133/Leaflet/master/README.md\n",
      "Error in Leaflet\n",
      "https://raw.githubusercontent.com/134/ecomfe/master/README.md\n",
      "Error in ecomfe\n",
      "https://raw.githubusercontent.com/135/BVLC/master/README.md\n",
      "Error in BVLC\n",
      "https://raw.githubusercontent.com/136/kenwheeler/master/README.md\n",
      "Error in kenwheeler\n",
      "https://raw.githubusercontent.com/137/justjavac/master/README.md\n",
      "Error in justjavac\n",
      "https://raw.githubusercontent.com/138/codepath/master/README.md\n",
      "Error in codepath\n",
      "https://raw.githubusercontent.com/139/mozilla/master/README.md\n",
      "Error in mozilla\n",
      "https://raw.githubusercontent.com/140/FezVrasta/master/README.md\n",
      "Error in FezVrasta\n",
      "https://raw.githubusercontent.com/141/shadowsocks/master/README.md\n",
      "Error in shadowsocks\n",
      "https://raw.githubusercontent.com/142/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/143/git/master/README.md\n",
      "Error in git\n",
      "https://raw.githubusercontent.com/144/gohugoio/master/README.md\n",
      "Error in gohugoio\n",
      "https://raw.githubusercontent.com/145/emberjs/master/README.md\n",
      "Error in emberjs\n",
      "https://raw.githubusercontent.com/146/rs/master/README.md\n",
      "Error in rs\n",
      "https://raw.githubusercontent.com/147/Polymer/master/README.md\n",
      "Error in Polymer\n",
      "https://raw.githubusercontent.com/148/zenorocha/master/README.md\n",
      "Error in zenorocha\n",
      "https://raw.githubusercontent.com/149/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/150/sindresorhus/master/README.md\n",
      "Error in sindresorhus\n",
      "https://raw.githubusercontent.com/151/tensorflow/master/README.md\n",
      "Error in tensorflow\n",
      "https://raw.githubusercontent.com/152/nvie/master/README.md\n",
      "Error in nvie\n",
      "https://raw.githubusercontent.com/153/donnemartin/master/README.md\n",
      "Error in donnemartin\n",
      "https://raw.githubusercontent.com/154/zeit/master/README.md\n",
      "Error in zeit\n",
      "https://raw.githubusercontent.com/155/vuejs/master/README.md\n",
      "Error in vuejs\n",
      "https://raw.githubusercontent.com/156/ReactiveCocoa/master/README.md\n",
      "Error in ReactiveCocoa\n",
      "https://raw.githubusercontent.com/157/serverless/master/README.md\n",
      "Error in serverless\n",
      "https://raw.githubusercontent.com/158/balderdashy/master/README.md\n",
      "Error in balderdashy\n",
      "https://raw.githubusercontent.com/159/plataformatec/master/README.md\n",
      "Error in plataformatec\n",
      "https://raw.githubusercontent.com/160/kamranahmedse/master/README.md\n",
      "Error in kamranahmedse\n",
      "https://raw.githubusercontent.com/161/Prinzhorn/master/README.md\n",
      "Error in Prinzhorn\n",
      "https://raw.githubusercontent.com/162/open-guides/master/README.md\n",
      "Error in open-guides\n",
      "https://raw.githubusercontent.com/163/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/164/herrbischoff/master/README.md\n",
      "Error in herrbischoff\n",
      "https://raw.githubusercontent.com/165/almasaeed2010/master/README.md\n",
      "Error in almasaeed2010\n",
      "https://raw.githubusercontent.com/166/numbbbbb/master/README.md\n",
      "Error in numbbbbb\n",
      "https://raw.githubusercontent.com/167/yahoo/master/README.md\n",
      "Error in yahoo\n",
      "https://raw.githubusercontent.com/168/mathiasbynens/master/README.md\n",
      "Error in mathiasbynens\n",
      "https://raw.githubusercontent.com/169/IanLunn/master/README.md\n",
      "Error in IanLunn\n",
      "https://raw.githubusercontent.com/170/fchollet/master/README.md\n",
      "Error in fchollet\n",
      "https://raw.githubusercontent.com/171/hexojs/master/README.md\n",
      "Error in hexojs\n",
      "https://raw.githubusercontent.com/172/JakeWharton/master/README.md\n",
      "Error in JakeWharton\n",
      "https://raw.githubusercontent.com/173/videojs/master/README.md\n",
      "Error in videojs\n",
      "https://raw.githubusercontent.com/174/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/175/FallibleInc/master/README.md\n",
      "Error in FallibleInc\n",
      "https://raw.githubusercontent.com/176/fastlane/master/README.md\n",
      "Error in fastlane\n",
      "https://raw.githubusercontent.com/177/astaxie/master/README.md\n",
      "Error in astaxie\n",
      "https://raw.githubusercontent.com/178/grafana/master/README.md\n",
      "Error in grafana\n",
      "https://raw.githubusercontent.com/179/Reactive-Extensions/master/README.md\n",
      "Error in Reactive-Extensions\n",
      "https://raw.githubusercontent.com/180/jgthms/master/README.md\n",
      "Error in jgthms\n",
      "https://raw.githubusercontent.com/181/huginn/master/README.md\n",
      "Error in huginn\n",
      "https://raw.githubusercontent.com/182/hammerjs/master/README.md\n",
      "Error in hammerjs\n",
      "https://raw.githubusercontent.com/183/opencv/master/README.md\n",
      "Error in opencv\n",
      "https://raw.githubusercontent.com/184/PhilJay/master/README.md\n",
      "Error in PhilJay\n",
      "https://raw.githubusercontent.com/185/syncthing/master/README.md\n",
      "Error in syncthing\n",
      "https://raw.githubusercontent.com/186/Kickball/master/README.md\n",
      "Error in Kickball\n",
      "https://raw.githubusercontent.com/187/railsware/master/README.md\n",
      "Error in railsware\n",
      "https://raw.githubusercontent.com/188/bumptech/master/README.md\n",
      "Error in bumptech\n",
      "https://raw.githubusercontent.com/189/bevacqua/master/README.md\n",
      "Error in bevacqua\n",
      "https://raw.githubusercontent.com/190/t4t5/master/README.md\n",
      "Error in t4t5\n",
      "https://raw.githubusercontent.com/191/koajs/master/README.md\n",
      "Error in koajs\n",
      "https://raw.githubusercontent.com/192/ripienaar/master/README.md\n",
      "Error in ripienaar\n",
      "https://raw.githubusercontent.com/193/request/master/README.md\n",
      "Error in request\n",
      "https://raw.githubusercontent.com/194/BradLarson/master/README.md\n",
      "Error in BradLarson\n",
      "https://raw.githubusercontent.com/195/sdmg15/master/README.md\n",
      "Error in sdmg15\n",
      "https://raw.githubusercontent.com/196/ziadoz/master/README.md\n",
      "Error in ziadoz\n",
      "https://raw.githubusercontent.com/197/aosabook/master/README.md\n",
      "Error in aosabook\n",
      "https://raw.githubusercontent.com/198/square/master/README.md\n",
      "Error in square\n",
      "https://raw.githubusercontent.com/199/angular/master/README.md\n",
      "Error in angular\n",
      "https://raw.githubusercontent.com/200/GitbookIO/master/README.md\n",
      "Error in GitbookIO\n",
      "https://raw.githubusercontent.com/201/photonstorm/master/README.md\n",
      "Error in photonstorm\n",
      "https://raw.githubusercontent.com/202/JetBrains/master/README.md\n",
      "Error in JetBrains\n",
      "https://raw.githubusercontent.com/203/SamyPesse/master/README.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in SamyPesse\n",
      "https://raw.githubusercontent.com/204/verekia/master/README.md\n",
      "Error in verekia\n",
      "https://raw.githubusercontent.com/205/usablica/master/README.md\n",
      "Error in usablica\n",
      "https://raw.githubusercontent.com/206/nostra13/master/README.md\n",
      "Error in nostra13\n",
      "https://raw.githubusercontent.com/207/ZuzooVn/master/README.md\n",
      "Error in ZuzooVn\n",
      "https://raw.githubusercontent.com/208/MaximAbramchuck/master/README.md\n",
      "Error in MaximAbramchuck\n",
      "https://raw.githubusercontent.com/209/ajaxorg/master/README.md\n",
      "Error in ajaxorg\n",
      "https://raw.githubusercontent.com/210/postcss/master/README.md\n",
      "Error in postcss\n",
      "https://raw.githubusercontent.com/211/bower/master/README.md\n",
      "Error in bower\n",
      "https://raw.githubusercontent.com/212/VundleVim/master/README.md\n",
      "Error in VundleVim\n",
      "https://raw.githubusercontent.com/213/Tencent/master/README.md\n",
      "Error in Tencent\n",
      "https://raw.githubusercontent.com/214/defunkt/master/README.md\n",
      "Error in defunkt\n",
      "https://raw.githubusercontent.com/215/kahun/master/README.md\n",
      "Error in kahun\n",
      "https://raw.githubusercontent.com/216/SnapKit/master/README.md\n",
      "Error in SnapKit\n",
      "https://raw.githubusercontent.com/217/greenrobot/master/README.md\n",
      "Error in greenrobot\n",
      "https://raw.githubusercontent.com/218/XX-net/master/README.md\n",
      "Error in XX-net\n",
      "https://raw.githubusercontent.com/219/pixijs/master/README.md\n",
      "Error in pixijs\n",
      "https://raw.githubusercontent.com/220/danielgindi/master/README.md\n",
      "Error in danielgindi\n",
      "https://raw.githubusercontent.com/221/ftlabs/master/README.md\n",
      "Error in ftlabs\n",
      "https://raw.githubusercontent.com/222/less/master/README.md\n",
      "Error in less\n",
      "https://raw.githubusercontent.com/223/petkaantonov/master/README.md\n",
      "Error in petkaantonov\n",
      "https://raw.githubusercontent.com/224/mitchellh/master/README.md\n",
      "Error in mitchellh\n",
      "https://raw.githubusercontent.com/225/SwiftyJSON/master/README.md\n",
      "Error in SwiftyJSON\n",
      "https://raw.githubusercontent.com/226/ryanmcdermott/master/README.md\n",
      "Error in ryanmcdermott\n",
      "https://raw.githubusercontent.com/227/symfony/master/README.md\n",
      "Error in symfony\n",
      "https://raw.githubusercontent.com/228/github/master/README.md\n",
      "Error in github\n",
      "https://raw.githubusercontent.com/229/ant-design/master/README.md\n",
      "Error in ant-design\n",
      "https://raw.githubusercontent.com/230/ApacheInfra/master/README.md\n",
      "Error in ApacheInfra\n",
      "https://raw.githubusercontent.com/231/lord/master/README.md\n",
      "Error in lord\n",
      "https://raw.githubusercontent.com/232/pugjs/master/README.md\n",
      "Error in pugjs\n",
      "https://raw.githubusercontent.com/233/spring-projects/master/README.md\n",
      "Error in spring-projects\n",
      "https://raw.githubusercontent.com/234/bcit-ci/master/README.md\n",
      "Error in bcit-ci\n",
      "https://raw.githubusercontent.com/235/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/236/alex/master/README.md\n",
      "Error in alex\n",
      "https://raw.githubusercontent.com/237/0xAX/master/README.md\n",
      "Error in 0xAX\n",
      "https://raw.githubusercontent.com/238/kriasoft/master/README.md\n",
      "Error in kriasoft\n",
      "https://raw.githubusercontent.com/239/alibaba/master/README.md\n",
      "Error in alibaba\n",
      "https://raw.githubusercontent.com/240/zeit/master/README.md\n",
      "Error in zeit\n",
      "https://raw.githubusercontent.com/241/tonsky/master/README.md\n",
      "Error in tonsky\n",
      "https://raw.githubusercontent.com/242/twitter/master/README.md\n",
      "Error in twitter\n",
      "https://raw.githubusercontent.com/243/react-boilerplate/master/README.md\n",
      "Error in react-boilerplate\n",
      "https://raw.githubusercontent.com/244/angular-ui/master/README.md\n",
      "Error in angular-ui\n",
      "https://raw.githubusercontent.com/245/dhg/master/README.md\n",
      "Error in dhg\n",
      "https://raw.githubusercontent.com/246/FreeCodeCampChina/master/README.md\n",
      "Error in FreeCodeCampChina\n",
      "https://raw.githubusercontent.com/247/dimsemenov/master/README.md\n",
      "Error in dimsemenov\n",
      "https://raw.githubusercontent.com/248/futurice/master/README.md\n",
      "Error in futurice\n",
      "https://raw.githubusercontent.com/249/Valloric/master/README.md\n",
      "Error in Valloric\n",
      "https://raw.githubusercontent.com/250/zxing/master/README.md\n",
      "Error in zxing\n",
      "https://raw.githubusercontent.com/251/isocpp/master/README.md\n",
      "Error in isocpp\n",
      "https://raw.githubusercontent.com/252/jashkenas/master/README.md\n",
      "Error in jashkenas\n",
      "https://raw.githubusercontent.com/253/jcjohnson/master/README.md\n",
      "Error in jcjohnson\n",
      "https://raw.githubusercontent.com/254/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/255/ElemeFE/master/README.md\n",
      "Error in ElemeFE\n",
      "https://raw.githubusercontent.com/256/racaljk/master/README.md\n",
      "Error in racaljk\n",
      "https://raw.githubusercontent.com/257/twbs/master/README.md\n",
      "Error in twbs\n",
      "https://raw.githubusercontent.com/258/quilljs/master/README.md\n",
      "Error in quilljs\n",
      "https://raw.githubusercontent.com/259/coreos/master/README.md\n",
      "Error in coreos\n",
      "https://raw.githubusercontent.com/260/Bilibili/master/README.md\n",
      "Error in Bilibili\n",
      "https://raw.githubusercontent.com/261/rstacruz/master/README.md\n",
      "Error in rstacruz\n",
      "https://raw.githubusercontent.com/262/dokku/master/README.md\n",
      "Error in dokku\n",
      "https://raw.githubusercontent.com/263/bitcoin/master/README.md\n",
      "Error in bitcoin\n",
      "https://raw.githubusercontent.com/264/webtorrent/master/README.md\n",
      "Error in webtorrent\n",
      "https://raw.githubusercontent.com/265/tornadoweb/master/README.md\n",
      "Error in tornadoweb\n",
      "https://raw.githubusercontent.com/266/square/master/README.md\n",
      "Error in square\n",
      "https://raw.githubusercontent.com/267/parse-community/master/README.md\n",
      "Error in parse-community\n",
      "https://raw.githubusercontent.com/268/dkhamsing/master/README.md\n",
      "Error in dkhamsing\n",
      "https://raw.githubusercontent.com/269/spring-projects/master/README.md\n",
      "Error in spring-projects\n",
      "https://raw.githubusercontent.com/270/airbnb/master/README.md\n",
      "Error in airbnb\n",
      "https://raw.githubusercontent.com/271/google/master/README.md\n",
      "Error in google\n",
      "https://raw.githubusercontent.com/272/limetext/master/README.md\n",
      "Error in limetext\n",
      "https://raw.githubusercontent.com/273/soimort/master/README.md\n",
      "Error in soimort\n",
      "https://raw.githubusercontent.com/274/jdg/master/README.md\n",
      "Error in jdg\n",
      "https://raw.githubusercontent.com/275/kriskowal/master/README.md\n",
      "Error in kriskowal\n",
      "https://raw.githubusercontent.com/276/tobiasahlin/master/README.md\n",
      "Error in tobiasahlin\n",
      "https://raw.githubusercontent.com/277/jaywcjlove/master/README.md\n",
      "Error in jaywcjlove\n",
      "https://raw.githubusercontent.com/278/reddit/master/README.md\n",
      "Error in reddit\n",
      "https://raw.githubusercontent.com/279/angular-ui/master/README.md\n",
      "Error in angular-ui\n",
      "https://raw.githubusercontent.com/280/jondot/master/README.md\n",
      "Error in jondot\n",
      "https://raw.githubusercontent.com/281/apache/master/README.md\n",
      "Error in apache\n",
      "https://raw.githubusercontent.com/282/Thibaut/master/README.md\n",
      "Error in Thibaut\n",
      "https://raw.githubusercontent.com/283/chjj/master/README.md\n",
      "Error in chjj\n",
      "https://raw.githubusercontent.com/284/knsv/master/README.md\n",
      "Error in knsv\n",
      "https://raw.githubusercontent.com/285/juliangarnier/master/README.md\n",
      "Error in juliangarnier\n",
      "https://raw.githubusercontent.com/286/designmodo/master/README.md\n",
      "Error in designmodo\n",
      "https://raw.githubusercontent.com/287/julianshapiro/master/README.md\n",
      "Error in julianshapiro\n",
      "https://raw.githubusercontent.com/288/akullpp/master/README.md\n",
      "Error in akullpp\n",
      "https://raw.githubusercontent.com/289/raywenderlich/master/README.md\n",
      "Error in raywenderlich\n",
      "https://raw.githubusercontent.com/290/postcss/master/README.md\n",
      "Error in postcss\n",
      "https://raw.githubusercontent.com/291/getsentry/master/README.md\n",
      "Error in getsentry\n",
      "https://raw.githubusercontent.com/292/angular/master/README.md\n",
      "Error in angular\n",
      "https://raw.githubusercontent.com/293/npm/master/README.md\n",
      "Error in npm\n",
      "https://raw.githubusercontent.com/294/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/295/hubotio/master/README.md\n",
      "Error in hubotio\n",
      "https://raw.githubusercontent.com/296/domnikl/master/README.md\n",
      "Error in domnikl\n",
      "https://raw.githubusercontent.com/297/ReactiveX/master/README.md\n",
      "Error in ReactiveX\n",
      "https://raw.githubusercontent.com/298/rwaldron/master/README.md\n",
      "Error in rwaldron\n",
      "https://raw.githubusercontent.com/299/mholt/master/README.md\n",
      "Error in mholt\n",
      "https://raw.githubusercontent.com/300/nolimits4web/master/README.md\n",
      "Error in nolimits4web\n",
      "https://raw.githubusercontent.com/301/madrobby/master/README.md\n",
      "Error in madrobby\n",
      "https://raw.githubusercontent.com/302/mochajs/master/README.md\n",
      "Error in mochajs\n",
      "https://raw.githubusercontent.com/303/Automattic/master/README.md\n",
      "Error in Automattic\n",
      "https://raw.githubusercontent.com/304/wg/master/README.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in wg\n",
      "https://raw.githubusercontent.com/305/ggreer/master/README.md\n",
      "Error in ggreer\n",
      "https://raw.githubusercontent.com/306/jlmakes/master/README.md\n",
      "Error in jlmakes\n",
      "https://raw.githubusercontent.com/307/jasmine/master/README.md\n",
      "Error in jasmine\n",
      "https://raw.githubusercontent.com/308/cheeriojs/master/README.md\n",
      "Error in cheeriojs\n",
      "https://raw.githubusercontent.com/309/bbatsov/master/README.md\n",
      "Error in bbatsov\n",
      "https://raw.githubusercontent.com/310/enyo/master/README.md\n",
      "Error in enyo\n",
      "https://raw.githubusercontent.com/311/CamDavidsonPilon/master/README.md\n",
      "Error in CamDavidsonPilon\n",
      "https://raw.githubusercontent.com/312/segmentio/master/README.md\n",
      "Error in segmentio\n",
      "https://raw.githubusercontent.com/313/RocketChat/master/README.md\n",
      "Error in RocketChat\n",
      "https://raw.githubusercontent.com/314/kripken/master/README.md\n",
      "Error in kripken\n",
      "https://raw.githubusercontent.com/315/ruby/master/README.md\n",
      "Error in ruby\n",
      "https://raw.githubusercontent.com/316/interagent/master/README.md\n",
      "Error in interagent\n",
      "https://raw.githubusercontent.com/317/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/318/matteocrippa/master/README.md\n",
      "Error in matteocrippa\n",
      "https://raw.githubusercontent.com/319/standard/master/README.md\n",
      "Error in standard\n",
      "https://raw.githubusercontent.com/320/braydie/master/README.md\n",
      "Error in braydie\n",
      "https://raw.githubusercontent.com/321/php/master/README.md\n",
      "Error in php\n",
      "https://raw.githubusercontent.com/322/songrotek/master/README.md\n",
      "Error in songrotek\n",
      "https://raw.githubusercontent.com/323/fouber/master/README.md\n",
      "Error in fouber\n",
      "https://raw.githubusercontent.com/324/twbs/master/README.md\n",
      "Error in twbs\n",
      "https://raw.githubusercontent.com/325/HubSpot/master/README.md\n",
      "Error in HubSpot\n",
      "https://raw.githubusercontent.com/326/wycats/master/README.md\n",
      "Error in wycats\n",
      "https://raw.githubusercontent.com/327/syl20bnr/master/README.md\n",
      "Error in syl20bnr\n",
      "https://raw.githubusercontent.com/328/riot/master/README.md\n",
      "Error in riot\n",
      "https://raw.githubusercontent.com/329/codemirror/master/README.md\n",
      "Error in codemirror\n",
      "https://raw.githubusercontent.com/330/dotnet/master/README.md\n",
      "Error in dotnet\n",
      "https://raw.githubusercontent.com/331/aymericdamien/master/README.md\n",
      "Error in aymericdamien\n",
      "https://raw.githubusercontent.com/332/ipader/master/README.md\n",
      "Error in ipader\n",
      "https://raw.githubusercontent.com/333/desandro/master/README.md\n",
      "Error in desandro\n",
      "https://raw.githubusercontent.com/334/naptha/master/README.md\n",
      "Error in naptha\n",
      "https://raw.githubusercontent.com/335/libgdx/master/README.md\n",
      "Error in libgdx\n",
      "https://raw.githubusercontent.com/336/PerfectlySoft/master/README.md\n",
      "Error in PerfectlySoft\n",
      "https://raw.githubusercontent.com/337/mongodb/master/README.md\n",
      "Error in mongodb\n",
      "https://raw.githubusercontent.com/338/legomushroom/master/README.md\n",
      "Error in legomushroom\n",
      "https://raw.githubusercontent.com/339/faif/master/README.md\n",
      "Error in faif\n",
      "https://raw.githubusercontent.com/340/kennethreitz/master/README.md\n",
      "Error in kennethreitz\n",
      "https://raw.githubusercontent.com/341/prettier/master/README.md\n",
      "Error in prettier\n",
      "https://raw.githubusercontent.com/342/kilimchoi/master/README.md\n",
      "Error in kilimchoi\n",
      "https://raw.githubusercontent.com/343/facebookarchive/master/README.md\n",
      "Error in facebookarchive\n",
      "https://raw.githubusercontent.com/344/ipython/master/README.md\n",
      "Error in ipython\n",
      "https://raw.githubusercontent.com/345/ccgus/master/README.md\n",
      "Error in ccgus\n",
      "https://raw.githubusercontent.com/346/MostlyAdequate/master/README.md\n",
      "Error in MostlyAdequate\n",
      "https://raw.githubusercontent.com/347/wagerfield/master/README.md\n",
      "Error in wagerfield\n",
      "https://raw.githubusercontent.com/348/etsy/master/README.md\n",
      "Error in etsy\n",
      "https://raw.githubusercontent.com/349/storybooks/master/README.md\n",
      "Error in storybooks\n",
      "https://raw.githubusercontent.com/350/Microsoft/master/README.md\n",
      "Error in Microsoft\n",
      "https://raw.githubusercontent.com/351/oneuijs/master/README.md\n",
      "Error in oneuijs\n",
      "https://raw.githubusercontent.com/352/gruntjs/master/README.md\n",
      "Error in gruntjs\n",
      "https://raw.githubusercontent.com/353/node-inspector/master/README.md\n",
      "Error in node-inspector\n",
      "https://raw.githubusercontent.com/354/drduh/master/README.md\n",
      "Error in drduh\n",
      "https://raw.githubusercontent.com/355/sindresorhus/master/README.md\n",
      "Error in sindresorhus\n",
      "https://raw.githubusercontent.com/356/puikinsh/master/README.md\n",
      "Error in puikinsh\n",
      "https://raw.githubusercontent.com/357/astaxie/master/README.md\n",
      "Error in astaxie\n",
      "https://raw.githubusercontent.com/358/textmate/master/README.md\n",
      "Error in textmate\n",
      "https://raw.githubusercontent.com/359/altercation/master/README.md\n",
      "Error in altercation\n",
      "https://raw.githubusercontent.com/360/diaspora/master/README.md\n",
      "Error in diaspora\n",
      "https://raw.githubusercontent.com/361/bolshchikov/master/README.md\n",
      "Error in bolshchikov\n",
      "https://raw.githubusercontent.com/362/tesseract-ocr/master/README.md\n",
      "Error in tesseract-ocr\n",
      "https://raw.githubusercontent.com/363/DefinitelyTyped/master/README.md\n",
      "Error in DefinitelyTyped\n",
      "https://raw.githubusercontent.com/364/caskroom/master/README.md\n",
      "Error in caskroom\n",
      "https://raw.githubusercontent.com/365/ionic-team/master/README.md\n",
      "Error in ionic-team\n",
      "https://raw.githubusercontent.com/366/remy/master/README.md\n",
      "Error in remy\n",
      "https://raw.githubusercontent.com/367/fzaninotto/master/README.md\n",
      "Error in fzaninotto\n",
      "https://raw.githubusercontent.com/368/substack/master/README.md\n",
      "Error in substack\n",
      "https://raw.githubusercontent.com/369/jiahaog/master/README.md\n",
      "Error in jiahaog\n",
      "https://raw.githubusercontent.com/370/Blankj/master/README.md\n",
      "Error in Blankj\n",
      "https://raw.githubusercontent.com/371/h5bp/master/README.md\n",
      "Error in h5bp\n",
      "https://raw.githubusercontent.com/372/adobe-fonts/master/README.md\n",
      "Error in adobe-fonts\n",
      "https://raw.githubusercontent.com/373/scottjehl/master/README.md\n",
      "Error in scottjehl\n",
      "https://raw.githubusercontent.com/374/terryum/master/README.md\n",
      "Error in terryum\n",
      "https://raw.githubusercontent.com/375/realm/master/README.md\n",
      "Error in realm\n",
      "https://raw.githubusercontent.com/376/influxdata/master/README.md\n",
      "Error in influxdata\n",
      "https://raw.githubusercontent.com/377/MengTo/master/README.md\n",
      "Error in MengTo\n",
      "https://raw.githubusercontent.com/378/github/master/README.md\n",
      "Error in github\n",
      "https://raw.githubusercontent.com/379/Shopify/master/README.md\n",
      "Error in Shopify\n",
      "https://raw.githubusercontent.com/380/janl/master/README.md\n",
      "Error in janl\n",
      "https://raw.githubusercontent.com/381/jaredhanson/master/README.md\n",
      "Error in jaredhanson\n",
      "https://raw.githubusercontent.com/382/jmcunningham/master/README.md\n",
      "Error in jmcunningham\n",
      "https://raw.githubusercontent.com/383/facebook/master/README.md\n",
      "Error in facebook\n",
      "https://raw.githubusercontent.com/384/julycoding/master/README.md\n",
      "Error in julycoding\n",
      "https://raw.githubusercontent.com/385/visionmedia/master/README.md\n",
      "Error in visionmedia\n",
      "https://raw.githubusercontent.com/386/chriskempson/master/README.md\n",
      "Error in chriskempson\n",
      "https://raw.githubusercontent.com/387/requirejs/master/README.md\n",
      "Error in requirejs\n",
      "https://raw.githubusercontent.com/388/shadowsocks/master/README.md\n",
      "Error in shadowsocks\n",
      "https://raw.githubusercontent.com/389/cmderdev/master/README.md\n",
      "Error in cmderdev\n",
      "https://raw.githubusercontent.com/390/yabwe/master/README.md\n"
     ]
    }
   ],
   "source": [
    "### Read the content of the readme file \n",
    "\n",
    "\n",
    "### https://codereview.stackexchange.com/questions/186614/text-cleaning-script-producing-lowercase-words-with-minimal-punctuation\n",
    "\n",
    "def cleaning(text):\n",
    "    text = re.sub(r'\\b(?:(?:https?|ftp)://)?\\w[\\w-]*(?:\\.[\\w-]+)+\\S*', ' ', text.lower())\n",
    "    words = re.findall(r'[a-z]+', text)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for repo in repos:\n",
    "    url = \"https://raw.githubusercontent.com\"+\"/\"+repo['username']+\"/\"+repo['reponame']+\"/master/README.md\"\n",
    "    try:\n",
    "        print(url)\n",
    "        conn = urlopen(url)\n",
    "        repo['read_me'] = cleaning(conn.read().decode('utf-8'))\n",
    "        count +=1\n",
    "    except:\n",
    "        try:\n",
    "            url = \"https://raw.githubusercontent.com\"+\"/\"+repo['username']+\"/\"+repo['reponame']+\"/master/readme.md\"\n",
    "            conn = urlopen(url)\n",
    "            repo['read_me'] = cleaning(conn.read().decode('utf-8'))    \n",
    "        except:\n",
    "            print(\"Error in {}\".format(repo['reponame']))\n",
    "            repo['read_me'] = None\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip the repositories, with sleep added to avoid putting too much pressure on the website.\n",
    "\n",
    "Some repositories without a master branch will not be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/17839973/constructing-pandas-dataframe-from-values-in-variables-gives-valueerror-if-usi\n",
    "df = pd.DataFrame.from_dict(repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\".data/Final_dataset.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 ###\n",
    "        ## Language Classification ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/Final_dataset_readme_content.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isnull(dataset['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isna(dataset['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[pd.isna(dataset['language'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it on a smal dataset \n",
    "\n",
    "# Used only the useful attributes \n",
    "columns = ['description', 'language', 'read_me', 'reponame', 'tags', 'username']\n",
    "df = dataset[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>read_me</th>\n",
       "      <th>reponame</th>\n",
       "      <th>tags</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The https://freeCodeCamp.com open source codeb...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>social banner build status pull requests welco...</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>nonprofits,certification,curriculum,react,node...</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The most popular HTML, CSS, and JavaScript fra...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>bootstrap slack bower version npm version buil...</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>javascript,css,html,bootstrap,jekyll-site,scss</td>\n",
       "      <td>twbs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description    language  \\\n",
       "0  The https://freeCodeCamp.com open source codeb...  JavaScript   \n",
       "1  The most popular HTML, CSS, and JavaScript fra...  JavaScript   \n",
       "\n",
       "                                             read_me      reponame  \\\n",
       "0  social banner build status pull requests welco...  freeCodeCamp   \n",
       "1  bootstrap slack bower version npm version buil...     bootstrap   \n",
       "\n",
       "                                                tags      username  \n",
       "0  nonprofits,certification,curriculum,react,node...  freeCodeCamp  \n",
       "1     javascript,css,html,bootstrap,jekyll-site,scss          twbs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['collection'] = df[['description','read_me', 'reponame', 'tags', 'username']].apply(lambda x: ' '.join(x.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['language'] = df['language']\n",
    "new_df['collection'] = df['collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('./data/language_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_lang = new_df[pd.notna(new_df['language'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df_lang[pd.isnull(new_df_lang['language'])]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'collection'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_lang.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmer and Limitizer \n",
    "\n",
    "# Convert it to a numpy array\n",
    "X = new_df_lang['collection'].values\n",
    "y = new_df_lang['language'].values\n",
    "\n",
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [lmtzr.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, \n",
    "                            stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifer = RandomForestClassifier(n_estimators = 1000, random_state=0)\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5852272727272727\n"
     ]
    }
   ],
   "source": [
    "classifer = LogisticRegression()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "classifer = GaussianNB()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4375\n"
     ]
    }
   ],
   "source": [
    "classifer = svm.SVC(gamma='scale')\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5113636363636364\n"
     ]
    }
   ],
   "source": [
    "classifer = tree.DecisionTreeClassifier()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's split the dataset into training and testing datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(new_df_lang['collection'], new_df_lang['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "\n",
    "count_vect.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_count = count_vect.fit_transform(train_x)\n",
    "xvalid_count = count_vect.fit_transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectors \n",
    "\n",
    "# Word Level TF_IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram Level TF_IDF\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# Character Level tf_idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x)\n",
    "xvalid_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Utility \n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    print(predictions)\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 22 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 33 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 14 15 15 15 15 15 15 15 15 15 15 28\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 14\n",
      " 15 15 15 14 15 15 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 14 15 15 15 15 15 14 15 15 28 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 14 15 15 15 15 15 15 15 36 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 14 15 15 22 14 15 15 15 15 14 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "Logistic Regression, TF-IDF Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "Logistic Regression, TF-IDF-Ngram Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "Logistic Regression, TF-IDF Vectors 0.004545454545454545\n"
     ]
    }
   ],
   "source": [
    "                ## Logistic Regression ##\n",
    "    \n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF Vectors {}\".format(accuracy1))\n",
    "\n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF-Ngram Vectors {}\".format(accuracy1))\n",
    "\n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF Vectors {}\".format(accuracy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, World TF-IDF Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 14 15 15 15 15 15 15 15 15 15 15 28\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 14\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 14 15 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 14 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, World N-Gram Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, Char Vectors 0.004545454545454545\n"
     ]
    }
   ],
   "source": [
    "                ## Naive Bayes ##\n",
    "\n",
    "# Naive Bayes on Word Level TF- IDF Vectors \n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, World TF-IDF Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, World N-Gram Vectors 0.004545454545454545\n",
      "[15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "NB, Char Vectors 0.004545454545454545\n"
     ]
    }
   ],
   "source": [
    "               ## SVM ##\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 22 12 15 29 15 12 15 12 24 15 12 29 36 15  2 24  2 15 15 12 32  3 15\n",
      " 14 15 15 15 11 28 15 33 15 15  2 28  4 24 15 32 32 15 28 22 15  4  5 33\n",
      " 15 12 15 15  2  4 15 15 15  4 28 15 14 11 15 15 22 11 14 15 15  0  4 11\n",
      " 15 35 15 15 15 15 15  2  4 15 15 15 22 15 15 15 15 15 15 14 15 15 24 14\n",
      "  4 12 12 14  4 15 14 15 15  4 15 15 15  5 15  2 29 15 22 15 15 14 22 24\n",
      " 24 15 11 29 12 33 14  5 15 15 35 12 35 15 33 32 33 15 15 12 15  2 15 35\n",
      " 29 14 28 14 15 33 37 14 15 22  2 29 11 15 15 12 11 29 15 11 22 33 15 11\n",
      " 14 15 15 15 15 28 15 14 36 15 15 12 22 28 15 28 35 29 33 15 15 22 29 15\n",
      "  2 15 14  2 15 33 14  5 15 15 15 14 15 15 14 15 15 11 14 32 15 28 29 22\n",
      " 14 29 15 15]\n",
      "NB, World TF-IDF Vectors 0.004545454545454545\n",
      "[15 22 29 15  5 29 15 15 33 24 21 15 22 36 15 13 29 28 15 37 15 15 35 12\n",
      " 12 15 15 15 15 12  5 35 15 15  4 15 15 15 15 14 28  4 28 15 35 35  7 15\n",
      " 14 12 15 12 12 28 15 15 32 13 15 15 14 15 15 15 15 11 15 15 15 11  4 22\n",
      " 15  4 15 24  5 15 13 33 34 29 29 15 12 36 15  5 35 24  5 15 15 15 15 14\n",
      "  5 28 15 14 15 15 12 15 15 14 15  5 12 15 15 28 29 35 24 15 15 15 14 29\n",
      " 14 15 15  5 22 22  5  2 15 15 15 33 15 15 28 13 15 15 15 15 37 35 15 15\n",
      " 33 14  2 14 15 33  5 14 15 12 35 29 14 37 35 12 11 15 15 35 33 33  2 15\n",
      " 14 14 36 11 15 15 15 15 11 15 15 12 12 15  2  2 15 34 14 35 12 22 29 15\n",
      " 29 12 22 12 20 35 22 34 15 15 15 14 15 15 22 14 15  5 14 15 37 15  9 28\n",
      " 15 12  5 15]\n",
      "NB, World N-Gram Vectors 0.004545454545454545\n",
      "[22 19 11 15 15 35 29 28 15 24 15  5 32 36 15 29  4 24 29 15 32 28  3 12\n",
      " 22 35 15 15 11 28  5 15 23 15 22 15 15 24 15 15 28 15 28 22  5 28  5 33\n",
      " 15 15 15 15 26 22 15 15 15 13 28 35 14 15 15  2 22 15 14 32 15 15 15 15\n",
      " 28 15 15 35 35 15 15 29 14 15 35 15 28 32 15 15 15 32 15 14 15  5 23 14\n",
      " 15 32  5 14 15 15 14 29 15 24 15 28 15 15  5 24 15 35  5  2 12 28 22 15\n",
      " 15 15 15  9 35 33 14 15 15 15 15 15 15 15 33 33 33 15 15 15 15 14  5 35\n",
      " 29 14 15 14 15 33 15 14 15 22 37 29 15 15 15  5 11 29 26 29 33 33 22 13\n",
      " 14  2 35 22 15 28 11 14 36 35  4 15 15 15  2 35 15 29 33 33 15 22 29 15\n",
      "  3 15 14 12 22 22 11 15 13 15 11 14 15  2 14 15 15 24 14  2 15  7 15 22\n",
      " 14 29 24 15]\n",
      "NB, Char Vectors 0.004545454545454545\n"
     ]
    }
   ],
   "source": [
    "              ## D Tree ##\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 22 15 15 12 15 15 15 15 15 15 15 15 15 15  4 15 15 15 15 15 29 28 15\n",
      " 14 15 15 15  2 28 15 22 15 15  4 15 15 15 15 15 15 15 15 22 15  4 15 15\n",
      " 15 15 15 15  4 15 15 15  2 15 28 15 14 15 15 15 11 11 15 15 15 14 35 15\n",
      " 15 15 35 15 15 15 15 22 15 15 33 15 22  4 15 15 15 15 11 15 15 15 11 14\n",
      " 15  2 15 14 15 15 14  2 15  4 15 15 15 15 15 15 11 15  2 15 15 15 22 15\n",
      " 15 15 11 15 14 22 14 15 15 15 15 15 15 15  2 15 22 15 15 15 15 15 12 15\n",
      " 29 14 15 14 15  5 15 14 15 22 14 15 15 15 15 15 11 15  5 29 22 15 15 15\n",
      " 14 11 14 15 15 28 15 14 11 15 15 15  4 15 15 15 15 15 22 15 15 22 15 15\n",
      "  2 15 14 15 15 22 14 15 15 15 15 14 15 15 11 15 15 15 14 15 15 15 15 28\n",
      " 15 29 15 15]\n",
      "RF, Word TF-IDF Vectors 0.004545454545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 22 15 15 15 15 15 15 33 15 15 15 15 12 15 15 15 28 15 15 15  4 15 15\n",
      " 15 15 15 15 15 15 15 22 15 15 28 15 15  4 15 15  5 15 28 22 15 15 15 15\n",
      " 15 15 15 15 28 28 15 15  5 15 15 15 14 15 15 15 15 15 15 15 15 14 14 28\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 28 15 15 15 15 15 15 15 15 15 28 14\n",
      " 15 15 15 14 22 15 28 15 15 15 15 15 15 15 15 28 29 15 15 15 15 15 22 15\n",
      " 15 15 15 14 14 15 15 15 15 15 15 15 15 15 28 15 22 15 15 15 15 15 15 15\n",
      " 15 14 12 15 15 15 15  2 15 12 15 29 29 15 15 15 15 15 15  5 15 15 15 15\n",
      " 14 14 14 15 15 15 15 15 15 15 15 15 28 15 15 28 15 15 22 15 15 22 15 15\n",
      "  4 15 14 15 15 22 15  4 15 15 15 14 15 15 28 15 15 15 14 15 15 15 15 15\n",
      " 15 15 15 15]\n",
      "RF, Word TF-IDF Vectors Ngram 0.004545454545454545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  2 22 15 15 15 15 15 15  4 15 15  4 36 15 11 15  2  4 15 15  5 15 15\n",
      " 14 15 15 15 28 28 15 22 15 15 15 28 15 15  2 15 15 15 28 22 15 29 15 22\n",
      " 15 15 15 15  2 11 15 15  4 22 28  2 14 15 15 15 15 11 11 15 15 11 14 14\n",
      " 28 15  2 15 15 15 15 22 14 15  4 15 33 15 15 15 15 15 15  4 15 15 15 14\n",
      "  5 14 15 14 15  2 14 15 15 24 15 15 15 15 15 15  2 15 15 24 15  4 22 15\n",
      " 15 14 11  4 15 15 14 15 15 15 15 15 15 15  2 24 15 15 15 15 15  2 15 15\n",
      "  3 14 15 14 15 15 15 14 15  2 15  4 15 15 15 15 35 15  2  3 22 28 11 14\n",
      " 14  3 15 15 15 28 15 15  2 15 15 15 15  2 15 22 15 15 22 15 15 33 15 15\n",
      " 15 15 14 15 28 22 14 15 15 15 15 14 15 15 12 15 15 11 14 15 15 15 15 15\n",
      " 15 29 22 15]\n",
      "RF, Word TF-IDF Vectors Ngram - Char 0.013636363636363636\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "## Random Forest \n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y,\n",
    "                xvalid_tfidf_ngram)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors Ngram {}\".format(accuracy))\n",
    "\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y,\n",
    "                xvalid_tfidf_ngram_chars)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors Ngram - Char {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/Final_dataset_source_file_content.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isnull(dataset['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isna(dataset['language']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>reponame</th>\n",
       "      <th>url</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>tags</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "      <th>description</th>\n",
       "      <th>collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>https://github.com/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>2017-06-24T15:56:17Z</td>\n",
       "      <td>nonprofits,certification,curriculum,react,node...</td>\n",
       "      <td>290k</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>The https://freeCodeCamp.com open source codeb...</td>\n",
       "      <td>name Managing Packages with npm dashedName man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>twbs</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>https://github.com/twbs/bootstrap</td>\n",
       "      <td>2017-06-24T15:40:21Z</td>\n",
       "      <td>javascript,css,html,bootstrap,jekyll-site,scss</td>\n",
       "      <td>112k</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>The most popular HTML, CSS, and JavaScript fra...</td>\n",
       "      <td>stylelint disable normalize css MIT License gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>EbookFoundation</td>\n",
       "      <td>free-programming-books</td>\n",
       "      <td>https://github.com/EbookFoundation/free-progra...</td>\n",
       "      <td>2017-06-23T01:09:34Z</td>\n",
       "      <td>education,list,books,resource</td>\n",
       "      <td>87.8k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freely available programming books</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         username                reponame  \\\n",
       "0           0     freeCodeCamp            freeCodeCamp   \n",
       "1           1             twbs               bootstrap   \n",
       "2           2  EbookFoundation  free-programming-books   \n",
       "\n",
       "                                                 url            updateDate  \\\n",
       "0       https://github.com/freeCodeCamp/freeCodeCamp  2017-06-24T15:56:17Z   \n",
       "1                  https://github.com/twbs/bootstrap  2017-06-24T15:40:21Z   \n",
       "2  https://github.com/EbookFoundation/free-progra...  2017-06-23T01:09:34Z   \n",
       "\n",
       "                                                tags  stars    language  \\\n",
       "0  nonprofits,certification,curriculum,react,node...   290k  JavaScript   \n",
       "1     javascript,css,html,bootstrap,jekyll-site,scss   112k  JavaScript   \n",
       "2                      education,list,books,resource  87.8k         NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0  The https://freeCodeCamp.com open source codeb...   \n",
       "1  The most popular HTML, CSS, and JavaScript fra...   \n",
       "2                 Freely available programming books   \n",
       "\n",
       "                                         collections  \n",
       "0  name Managing Packages with npm dashedName man...  \n",
       "1  stylelint disable normalize css MIT License gi...  \n",
       "2                                                NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used only the useful attributes \n",
    "columns = ['description', 'language', 'reponame', 'tags', 'username', 'collections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>reponame</th>\n",
       "      <th>tags</th>\n",
       "      <th>username</th>\n",
       "      <th>collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The https://freeCodeCamp.com open source codeb...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>nonprofits,certification,curriculum,react,node...</td>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>name Managing Packages with npm dashedName man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The most popular HTML, CSS, and JavaScript fra...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>javascript,css,html,bootstrap,jekyll-site,scss</td>\n",
       "      <td>twbs</td>\n",
       "      <td>stylelint disable normalize css MIT License gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description    language  \\\n",
       "0  The https://freeCodeCamp.com open source codeb...  JavaScript   \n",
       "1  The most popular HTML, CSS, and JavaScript fra...  JavaScript   \n",
       "\n",
       "       reponame                                               tags  \\\n",
       "0  freeCodeCamp  nonprofits,certification,curriculum,react,node...   \n",
       "1     bootstrap     javascript,css,html,bootstrap,jekyll-site,scss   \n",
       "\n",
       "       username                                        collections  \n",
       "0  freeCodeCamp  name Managing Packages with npm dashedName man...  \n",
       "1          twbs  stylelint disable normalize css MIT License gi...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset[columns]\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['collection'] = df[['description', 'reponame', 'tags', 'username','collections']].apply(lambda x: ' '.join(x.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['language'] = df['language']\n",
    "new_df['collection'] = df['collection']\n",
    "new_df.to_csv(\"./data/language_Dataset_source_content.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>The https://freeCodeCamp.com open source codeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>The most popular HTML, CSS, and JavaScript fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Freely available programming books free-progr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                         collection\n",
       "0  JavaScript  The https://freeCodeCamp.com open source codeb...\n",
       "1  JavaScript  The most popular HTML, CSS, and JavaScript fra...\n",
       "2         NaN   Freely available programming books free-progr..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_lang = new_df[pd.notna(new_df['language'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df_lang[pd.isnull(new_df_lang['language'])]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmer and Limitizer \n",
    "\n",
    "# Convert it to a numpy array\n",
    "X = new_df_lang['collection'].values\n",
    "y = new_df_lang['language'].values\n",
    "\n",
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [lmtzr.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, \n",
    "                            stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6988636363636364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifer = RandomForestClassifier(n_estimators = 1000, random_state=0)\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6761363636363636\n"
     ]
    }
   ],
   "source": [
    "classifer = LogisticRegression()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4943181818181818\n"
     ]
    }
   ],
   "source": [
    "classifer = GaussianNB()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4659090909090909\n"
     ]
    }
   ],
   "source": [
    "classifer = svm.SVC(gamma='scale')\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5852272727272727\n"
     ]
    }
   ],
   "source": [
    "classifer = tree.DecisionTreeClassifier()\n",
    "classifer.fit(X_train, y_train)\n",
    "y_pred = classifer.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's split the dataset into training and testing datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(new_df_lang['collection'], new_df_lang['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "\n",
    "count_vect.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_count = count_vect.fit_transform(train_x)\n",
    "xvalid_count = count_vect.fit_transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectors \n",
    "\n",
    "# Word Level TF_IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram Level TF_IDF\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# Character Level tf_idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(new_df_lang['collection'])\n",
    "\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x)\n",
    "xvalid_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Utility \n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    print(predictions)\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 11 11 11 11 11 11 10 11 11 11  7 11 11 11 11 11 11 24 18 11  7 11\n",
      " 11  7 11 11 10 18 11 11 11 10 11 11 11 11 11 11 10 11 10 11 18 11 18 11\n",
      " 11 11 11 18 18 11 11 18 11 11 11 11 11 18 24 11 10 11 11  0 11 11 11 10\n",
      " 18 11 11 11 11 11 11 11 11 11 24 33 11 11 11 18 11 11 11 11 11 11 11 11\n",
      " 24 11 26 11 11 11 11 11 11 24 11 10 11 11 11 18 11 11 11 11 10 30 20 10\n",
      " 11 11 11 10 11 11 11 11 11 11 11 11 10 11 11 11 24 11 26 11 11 10 11 11\n",
      " 11 10 11 11 11 11 11 11 11 18 11 33 18 11 11  0 11 11  7 11 11 11 11 11\n",
      " 18 24 11 11 10 11 11 11 11 11 11 11 24 11 11 10 11 11 11 11 10 24 11  0\n",
      " 11 11 18 11 11 11 11 11 10 10 11 11 11  7 11 11 18 24 11 11 11 11 11 11\n",
      " 11 24 11 11]\n",
      "Logistic Regression, TF-IDF Vectors 0.00909090909090909\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11]\n",
      "Logistic Regression, TF-IDF-Ngram Vectors 0.00909090909090909\n",
      "[26 11 11 11 11 11 11 11 26 11 26 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 26 11 26 11 11 11 11 26 11 11 11 11 26 11 26 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 26 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 26 11 11 26 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 26 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 26 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 26 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 26 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11]\n",
      "Logistic Regression, TF-IDF Vectors 0.00909090909090909\n"
     ]
    }
   ],
   "source": [
    "                ## Logistic Regression ##\n",
    "    \n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF Vectors {}\".format(accuracy1))\n",
    "\n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF-Ngram Vectors {}\".format(accuracy1))\n",
    "\n",
    "accuracy1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf)\n",
    "\n",
    "print(\"Logistic Regression, TF-IDF Vectors {}\".format(accuracy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 11 11 11 11 11 11 10 11 11 11 11 11 11 11 11 11 11 24 18 11 11 11\n",
      " 11 11 11 11 10 18 11 11 11 10 11 11 11 11 11 11 10 11 11 11 18 11 11 11\n",
      " 11 11 11 11 18 11 11 18 11 11 11 11 11 18 11 11 10 11 11 11 11 11 11 10\n",
      " 18 11 11 11 11 11 11 11 11 11 11 11 11 11 11 18 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 10 11 11 11 18 11 11 11 11 10 11 11 10\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 24 11 11 11 11 10 11 11\n",
      " 11 10 11 11 11 11 11 11 11 18 11 11 18 11 11 11 11 11 11 11 11 11 11 11\n",
      " 18 11 11 11 11 11 11 11 11 11 11 11 11 11 11 10 11 11 11 11 10 11 11 11\n",
      " 11 11 18 11 11 11 11 11 10 10 11 11 11 11 11 11 18 24 11 11 11 11 11 11\n",
      " 11 24 11 11]\n",
      "NB, World TF-IDF Vectors 0.00909090909090909\n",
      "[10 11 11 11 11 11 11 11 10 11 11 11 11 11 11 11 11 11 11 24 18 11 11 11\n",
      " 11 11 11 11 10 18 11 11 11 10 11 11 11 11 11 11 10 11 11 11 18 10 30 11\n",
      " 11 11 11 11 18 11 11 18 11 11 11 11 11 18 11 11 10 11 11 11 26 11 11 10\n",
      " 18 11 11 11 11 11 11 11 11  7 24 11 10 11 11 18 11 11 11 11 11 11 11 11\n",
      " 24 11 11 11 11 11 11  7 11 24 11  0 10 11 11 18 11 11 11 11 10 11 11 10\n",
      " 11 11 11 10 11 11 11 11  7 11 11 11 10 11 10 11 24 24 11 11 11 10 11  0\n",
      " 11 10 11 11 11 11 11 11 11 18 11 11 18 11 11 24 11 11 11 11 11 11 11 11\n",
      " 18 24 26 11 10 11 11 11 11 11 11 11 24 11 11 10 11 11 11 11 10 24 11 11\n",
      " 11 11 18 11 11 11 11  7 10 10 11 18 11 11 11 11 30 24 10 11 11 24 11  7\n",
      " 11 24 11 11]\n",
      "NB, World N-Gram Vectors 0.013636363636363636\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 18 18 11 11 11 11\n",
      " 11 11 11 11]\n",
      "NB, Char Vectors 0.00909090909090909\n"
     ]
    }
   ],
   "source": [
    "               ## Naive Bayes ##\n",
    "\n",
    "# Naive Bayes on Word Level TF- IDF Vectors \n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11]\n",
      "NB, World TF-IDF Vectors 0.00909090909090909\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11]\n",
      "NB, World N-Gram Vectors 0.00909090909090909\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11]\n",
      "NB, Char Vectors 0.00909090909090909\n"
     ]
    }
   ],
   "source": [
    "               ## SVM ##\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  8 11 32  5 11 11 30 10 11 26  5 11 11 11  0  2 11 11 24 18 11 30  3\n",
      " 11 11 11  2 10 18  1 11 11 10 11 11  6 11 32 11 10  8 10 11 18 11 11  3\n",
      "  3  8 11 18 30 30  8 18 11  2  0  7 11 30 24 11 10 11 11  0 11 11 26 10\n",
      " 30 11 30 11  3 26 11 24 11  7 11 33 11 11  8 18 11 11  3 11 11  3  3  8\n",
      " 11 11 26 26 11 11  0 11 11 24 11 11 11  3 30 18 11 30 11 11 10 30 20 10\n",
      " 11 11  8 26 15 32 11 11 11 20  8  4  2  8 11  4  8 33 26 11 33 10 10  7\n",
      "  2 10 11  8 11 11 24 20  8 18 11 29 18 11 11  2 11 11  7  8 11  0 10  8\n",
      " 18 29 20 11 10 26 11 11 20 11 11  8 13 11 11 10  8 11 11 26 10 24 20 30\n",
      "  8 11 30  7 11 11 11  4 10 10  3 32  0 11 11 11 18  8 11 29 11  3 11  2\n",
      " 11 24 26 11]\n",
      "NB, World TF-IDF Vectors 0.00909090909090909\n",
      "[ 7 33 11 11  7 11 11 32 10 11 24 11 29 11 11  2  2 11  3 24 26 11  1 11\n",
      "  3  7 11 33 10 18 18  7 26 10 11 11 11 33 33 11 10 33 10 11 18 11 18 11\n",
      " 11 33 11 18 30  1 30 33 11 11  0 15 11 30 33 11 10 11 11  2  8 32  8 10\n",
      " 30 11 11 11  3  1 11  0 11  7 33 33 11 11 11 18 33 26 33 11 11 11 11 11\n",
      " 24 33 33  7  5  1  0 32  8 24 11  0 33  8 18 18 11  0 11  7 10 18 20 10\n",
      "  8 11  8  1 11 11 11 11 20 11 20  1 33 30  7 11 24  2 33 11  4 10 11  7\n",
      " 11 10 11 11 11 11 33 20 11 18 33 30 18 33 11  0 11 11  0 16 11  2 10  3\n",
      " 18 33  8 11 11 33 11 33 32 33 11  3 24 11  8 26 33 11 11 24  2 24  7  2\n",
      "  8 26 18 11 11 11 11 32 10 10  2  0  2  1 11 11 30  2 11  5 11 11 11  7\n",
      " 11 24 11  4]\n",
      "NB, World N-Gram Vectors 0.01818181818181818\n",
      "[24 26 11 11 11 33 24  3  7 30 24 20 26 11 11  0  3 11 11 24 18 11 33 11\n",
      "  3  7 11 30 23 30 11 11 11 10 20 11 11 11  8  8 10 11 10  2 19 31 30 11\n",
      " 11  3 11 11 30 30  3 30 10  8 11 30 30 18 24 11 10 11 11  0 11 24 11  0\n",
      "  3 11 33 26  3  8 11 32 11  7  2 33  8  8 11 18 10 24  3 11 11 11 11 11\n",
      "  2  2 26  2 11  7  1 11 11 24 11  7  8 11  7 19 32 11 11 11 10  3 20 10\n",
      " 11 11 31  2 11 11 30  8  8 11 29 29 24  2 11  8 11  8 26 11 11 10 10 11\n",
      " 11 32 11 16 32 11 11 20  7 18  8 33 18 11 11  0 11 11 25 11 11 11  3  4\n",
      " 18 24 11 11 10 11 11 29 24 11 10 11 24  3 11 10 10 11 30 26 10 24 11 10\n",
      "  8 11 18 11 10 11 10 11 10 10  8  7  7  8 11  3 30 24  2 10 32 32  8 24\n",
      "  8 24 11 11]\n",
      "NB, Char Vectors 0.00909090909090909\n"
     ]
    }
   ],
   "source": [
    "              ## D Tree ##\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"NB, World TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf_ngram,\n",
    "                      train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, World N-Gram Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(tree.DecisionTreeClassifier(), xtrain_tfidf_ngram_chars,\n",
    "                      train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, Char Vectors {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 11 11 11 11 11 11 11 10 11  3 20 20 11 11 11  0 11 11 24 18 11 10 11\n",
      " 11  7 11 11 10 30 26 11 11 10 11 11 11 11 11 11 10 26  8 24 18 11 30 11\n",
      " 11 11 11 18 30 30 20 30 11 11 11 24 11 30 24 11 10 11 11  0 11 24 11 10\n",
      " 30 11 11 11 11  7 11 24 11 11 24 33 11 11 11 18  2 24  8 11 11 11 11 11\n",
      " 24 11 26 33 11  7  0 11 11 24 11  0  2 11 18 30 11  0 11 11 10 20 20 10\n",
      " 11 11 11  2  8 11 11 11 11 11 29 29 10 20 11 11 16 11 26 11 11 10 10 11\n",
      " 11 10 11 11 11 11 11 20 11 30 11 33 18  8 11  0 11 11  7 26 11  0 10 11\n",
      " 18 24 11 11 10 11 11  8 20 11 11 26 24 11 11 10 26 11 11 18 10 24 11  0\n",
      " 11 11 30 11 11 11 11 11 10 10 11 30  0 30 11 11 18 24 11 11 11 11 11 10\n",
      " 11 24 11 11]\n",
      "RF, Word TF-IDF Vectors 0.00909090909090909\n",
      "[10 11 11 11 11 11  7 11  7 11 24 11  7 11 11  2 11 11 11 24 18 11  7 11\n",
      " 20  7 11 11 10 18 18 11 11 10 31 11 11 10 17 11 10 33 10 11 18 10 30 11\n",
      " 11 11 11 18 30 30 30 18 11 11 11 24 11 30 24 11 10 11 11  2 11 11 11 10\n",
      " 18 11 11 11  3 26 11  0 11  7 24 33 11 11 11 18  2 11 33 11 11 11 11 11\n",
      "  2 11 33  7 11  7 11 11 11 24 11  0 11 11 18 30 11  0 11 11 10 18 20 10\n",
      " 11 11 11  7 11 11 11 11 11 11 20  7  2 30 11 11 24  2 33 11 11 10 11  0\n",
      " 11 10 11 11 11 11 33 20 11 30 33 11 18 33 11  0 11 11  0 16 11  2 28  3\n",
      " 30 24 11 11 10 11 11  7 30 26 11 29 24 11 11 10 33 11 11 24 10 24 11  2\n",
      " 11 11 30 11 11 11 11  7 10  0 11 18  0 26 11 11 30  2 11 11 11 11 11  7\n",
      " 11 24 11 11]\n",
      "RF, Word TF-IDF Vectors Ngram 0.02727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 11 11 11 11 11 11 10 11 18 24  7 10 11 11  2 11  8 11 18 11  2 11\n",
      " 24  2 11  2 10 30 11 11 11 10 11 11 11 11 11 11 10 26 10 11 18 11  9 11\n",
      " 11 11 11 26 30 11 11 30 11 11 11 24 11 30 24 11 10 11 11  0 11 26 11 10\n",
      " 30 11 11 11  3 24 11 11 11  2 11 33 10 11 11 18  2  0 18 11 11 11 11 11\n",
      "  0 11 26 11 11 18 24  8 11 24 11 11 11 11 11 11 11  2 11 11 10 30 20 10\n",
      " 11 11 11 24 11 11 11 11 11 11 18 24  8 10  0 11 24 11 26 11 11 10 11 11\n",
      " 11 10 11 24 11 11  1 20 11 30 11 26 18 11 11  0 11 11 11  3 11  0 11 26\n",
      " 18 11 11 11 10 11 11 11 26 18 11 11 24 11 11 10 10 11 11 26 10 11 11 11\n",
      " 11 11 30 11 11 11 11 11 10 10 11 11  0  3 11 11 30 24 18 26 11 11 11  3\n",
      " 11 24 11 11]\n",
      "RF, Word TF-IDF Vectors Ngram - Char 0.00909090909090909\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "## Random Forest \n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y,\n",
    "                xvalid_tfidf)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors {}\".format(accuracy))\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y,\n",
    "                xvalid_tfidf_ngram)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors Ngram {}\".format(accuracy))\n",
    "\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y,\n",
    "                xvalid_tfidf_ngram_chars)\n",
    "\n",
    "print(\"RF, Word TF-IDF Vectors Ngram - Char {}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
